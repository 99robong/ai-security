{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"colab":{"name":"tensor_tutorial.ipynb의 사본","provenance":[{"file_id":"https://github.com/pytorch/tutorials/blob/gh-pages/_downloads/tensor_tutorial.ipynb","timestamp":1569826719936}],"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"code","metadata":{"id":"n3_tOwGo8-MP","colab_type":"code","colab":{}},"source":["%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4-3uM7A_8-MS","colab_type":"text"},"source":["\n","What is PyTorch?\n","================\n","\n","It’s a Python-based scientific computing package targeted at two sets of\n","audiences:\n","\n","-  A replacement for NumPy to use the power of GPUs\n","-  a deep learning research platform that provides maximum flexibility\n","   and speed\n","\n","Getting Started\n","---------------\n","\n","Tensors\n","^^^^^^^\n","\n","Tensors are similar to NumPy’s ndarrays, with the addition being that\n","Tensors can also be used on a GPU to accelerate computing.\n","\n"]},{"cell_type":"code","metadata":{"id":"SVtJfVwh8-MT","colab_type":"code","colab":{}},"source":["from __future__ import print_function\n","import torch"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hMnfcsGy8-MU","colab_type":"text"},"source":["Construct a 5x3 matrix, uninitialized:\n","\n"]},{"cell_type":"code","metadata":{"id":"7iJq8ecw8-MV","colab_type":"code","outputId":"91f66399-8e0e-415e-89e4-759410c46967","executionInfo":{"status":"ok","timestamp":1569826553501,"user_tz":-540,"elapsed":637,"user":{"displayName":"","photoUrl":"","userId":""}},"colab":{"base_uri":"https://localhost:8080/","height":107}},"source":["x = torch.empty(5, 3)\n","print(x)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([[7.2373e-36, 0.0000e+00, 3.3631e-44],\n","        [0.0000e+00,        nan, 0.0000e+00],\n","        [1.1578e+27, 1.1362e+30, 7.1547e+22],\n","        [4.5828e+30, 1.2121e+04, 7.1846e+22],\n","        [9.2198e-39, 0.0000e+00, 0.0000e+00]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7zfOUJ8g8-MW","colab_type":"text"},"source":["Construct a randomly initialized matrix:\n","\n"]},{"cell_type":"code","metadata":{"id":"2cfZ0pGz8-MX","colab_type":"code","outputId":"16c01e49-0b72-4a59-d578-0e2beba1824b","executionInfo":{"status":"ok","timestamp":1569826563109,"user_tz":-540,"elapsed":645,"user":{"displayName":"","photoUrl":"","userId":""}},"colab":{"base_uri":"https://localhost:8080/","height":107}},"source":["x = torch.rand(5, 3)\n","print(x)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([[0.5545, 0.8511, 0.7455],\n","        [0.8508, 0.1839, 0.1617],\n","        [0.6544, 0.5593, 0.8080],\n","        [0.4769, 0.1439, 0.3571],\n","        [0.4710, 0.2459, 0.7352]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Pw00ezLl8-MY","colab_type":"text"},"source":["Construct a matrix filled zeros and of dtype long:\n","\n"]},{"cell_type":"code","metadata":{"id":"osgkecod8-MZ","colab_type":"code","outputId":"28318045-b399-4417-cd9f-f0f20d916b6e","executionInfo":{"status":"ok","timestamp":1569826595605,"user_tz":-540,"elapsed":662,"user":{"displayName":"","photoUrl":"","userId":""}},"colab":{"base_uri":"https://localhost:8080/","height":107}},"source":["x = torch.zeros(5, 3, dtype=torch.long)\n","print(x)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([[0, 0, 0],\n","        [0, 0, 0],\n","        [0, 0, 0],\n","        [0, 0, 0],\n","        [0, 0, 0]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RqymlLw48-Ma","colab_type":"text"},"source":["Construct a tensor directly from data:\n","\n"]},{"cell_type":"code","metadata":{"id":"kGv2RwPY8-Ma","colab_type":"code","outputId":"8dbe1ea4-8c84-4b21-834d-d5d8bcc77dba","executionInfo":{"status":"ok","timestamp":1569826602039,"user_tz":-540,"elapsed":686,"user":{"displayName":"","photoUrl":"","userId":""}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["x = torch.tensor([5.5, 3])\n","print(x)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([5.5000, 3.0000])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TUyXtt5j8-Mc","colab_type":"text"},"source":["or create a tensor based on an existing tensor. These methods\n","will reuse properties of the input tensor, e.g. dtype, unless\n","new values are provided by user\n","\n"]},{"cell_type":"code","metadata":{"id":"Ed62JgmQ8-Mc","colab_type":"code","outputId":"b21a8a76-155b-4ba3-a986-9a7ac3b50221","executionInfo":{"status":"ok","timestamp":1569826608158,"user_tz":-540,"elapsed":722,"user":{"displayName":"","photoUrl":"","userId":""}},"colab":{"base_uri":"https://localhost:8080/","height":197}},"source":["x = x.new_ones(5, 3, dtype=torch.double)      # new_* methods take in sizes\n","print(x)\n","\n","x = torch.randn_like(x, dtype=torch.float)    # override dtype!\n","print(x)                                      # result has the same size"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([[1., 1., 1.],\n","        [1., 1., 1.],\n","        [1., 1., 1.],\n","        [1., 1., 1.],\n","        [1., 1., 1.]], dtype=torch.float64)\n","tensor([[ 3.2210,  0.4677,  0.1620],\n","        [ 0.6463, -0.3989,  1.0596],\n","        [-1.3802,  1.2681, -0.3325],\n","        [ 0.2440, -1.3145, -0.0504],\n","        [-1.3720,  0.7129,  1.1472]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SJGneAJl8-Me","colab_type":"text"},"source":["Get its size:\n","\n"]},{"cell_type":"code","metadata":{"id":"cEaAbnIY8-Me","colab_type":"code","colab":{}},"source":["print(x.size())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eUJ2D9uu8-Mg","colab_type":"text"},"source":["<div class=\"alert alert-info\"><h4>Note</h4><p>``torch.Size`` is in fact a tuple, so it supports all tuple operations.</p></div>\n","\n","Operations\n","^^^^^^^^^^\n","There are multiple syntaxes for operations. In the following\n","example, we will take a look at the addition operation.\n","\n","Addition: syntax 1\n","\n"]},{"cell_type":"code","metadata":{"id":"u7-eSz_b8-Mg","colab_type":"code","colab":{}},"source":["y = torch.rand(5, 3)\n","print(x + y)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l6vtY2PO8-Mi","colab_type":"text"},"source":["Addition: syntax 2\n","\n"]},{"cell_type":"code","metadata":{"id":"O55_EU8x8-Mi","colab_type":"code","colab":{}},"source":["print(torch.add(x, y))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nGWvh7b38-Mj","colab_type":"text"},"source":["Addition: providing an output tensor as argument\n","\n"]},{"cell_type":"code","metadata":{"id":"b1eI1fKB8-Mk","colab_type":"code","colab":{}},"source":["result = torch.empty(5, 3)\n","torch.add(x, y, out=result)\n","print(result)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WcYljK0F8-Ml","colab_type":"text"},"source":["Addition: in-place\n","\n"]},{"cell_type":"code","metadata":{"id":"TLD1MV__8-Mm","colab_type":"code","colab":{}},"source":["# adds x to y\n","y.add_(x)\n","print(y)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AcbrHBvo8-Mn","colab_type":"text"},"source":["<div class=\"alert alert-info\"><h4>Note</h4><p>Any operation that mutates a tensor in-place is post-fixed with an ``_``.\n","    For example: ``x.copy_(y)``, ``x.t_()``, will change ``x``.</p></div>\n","\n","You can use standard NumPy-like indexing with all bells and whistles!\n","\n"]},{"cell_type":"code","metadata":{"id":"tGtWi-iX8-Mo","colab_type":"code","colab":{}},"source":["print(x[:, 1])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zF3OGaVB8-Mp","colab_type":"text"},"source":["Resizing: If you want to resize/reshape tensor, you can use ``torch.view``:\n","\n"]},{"cell_type":"code","metadata":{"id":"S87M3KGW8-Mq","colab_type":"code","colab":{}},"source":["x = torch.randn(4, 4)\n","y = x.view(16)\n","z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n","print(x.size(), y.size(), z.size())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Bghtkf7u8-Ms","colab_type":"text"},"source":["If you have a one element tensor, use ``.item()`` to get the value as a\n","Python number\n","\n"]},{"cell_type":"code","metadata":{"id":"CUqa9rEg8-Mt","colab_type":"code","colab":{}},"source":["x = torch.randn(1)\n","print(x)\n","print(x.item())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NGwfDLtM8-Mu","colab_type":"text"},"source":["**Read later:**\n","\n","\n","  100+ Tensor operations, including transposing, indexing, slicing,\n","  mathematical operations, linear algebra, random numbers, etc.,\n","  are described\n","  `here <http://pytorch.org/docs/torch>`_.\n","\n","NumPy Bridge\n","------------\n","\n","Converting a Torch Tensor to a NumPy array and vice versa is a breeze.\n","\n","The Torch Tensor and NumPy array will share their underlying memory\n","locations, and changing one will change the other.\n","\n","Converting a Torch Tensor to a NumPy Array\n","^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","\n"]},{"cell_type":"code","metadata":{"id":"mtUpyvru8-Mv","colab_type":"code","colab":{}},"source":["a = torch.ones(5)\n","print(a)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"adQzUbrR8-Mx","colab_type":"code","colab":{}},"source":["b = a.numpy()\n","print(b)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DQe7JFtE8-M0","colab_type":"text"},"source":["See how the numpy array changed in value.\n","\n"]},{"cell_type":"code","metadata":{"id":"bXruI74X8-M0","colab_type":"code","colab":{}},"source":["a.add_(1)\n","print(a)\n","print(b)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kQ7qKorq8-M2","colab_type":"text"},"source":["Converting NumPy Array to Torch Tensor\n","^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","See how changing the np array changed the Torch Tensor automatically\n","\n"]},{"cell_type":"code","metadata":{"id":"Jv0VVSNp8-M2","colab_type":"code","colab":{}},"source":["import numpy as np\n","a = np.ones(5)\n","b = torch.from_numpy(a)\n","np.add(a, 1, out=a)\n","print(a)\n","print(b)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7m14y7qb8-M3","colab_type":"text"},"source":["All the Tensors on the CPU except a CharTensor support converting to\n","NumPy and back.\n","\n","CUDA Tensors\n","------------\n","\n","Tensors can be moved onto any device using the ``.to`` method.\n","\n"]},{"cell_type":"code","metadata":{"id":"o2JDC9vP8-M4","colab_type":"code","colab":{}},"source":["# let us run this cell only if CUDA is available\n","# We will use ``torch.device`` objects to move tensors in and out of GPU\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")          # a CUDA device object\n","    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n","    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n","    z = x + y\n","    print(z)\n","    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"],"execution_count":0,"outputs":[]}]}